{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_task_model import Multi_Model\n",
    "from transformers import InputExample\n",
    "from transformers import (WEIGHTS_NAME, BertConfig, BertModel, BertTokenizer,\n",
    "                          RobertaConfig,RobertaModel,RobertaTokenizer,\n",
    "                          XLNetConfig,XLNetModel,XLNetTokenizer)\n",
    "from torch.utils.data import TensorDataset\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args=parser.parse_known_args()[0]\n",
    "args.model_type=\"bert\"\n",
    "args.config_name=\"./bert-base-uncased/bert-base-uncased-config.json\"\n",
    "args.tokenizer_name=\"./bert-base-uncased/bert-base-uncased-vocab.txt\"\n",
    "args.model_name_or_path=\"./bert-base-uncased/bert-base-uncased-pytorch_model.bin\"\n",
    "args.all_task=True\n",
    "args.aggression_attack_task=False\n",
    "args.aggression_toxicity_task=False\n",
    "args.attack_toxicity_task=False\n",
    "\n",
    "config=BertConfig.from_pretrained(args.config_name ,num_labels=2,finetuning_task=\"multi_task\")\n",
    "tokenizer = BertTokenizer.from_pretrained(args.tokenizer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "text_a=\"i have a dick, its bigger than yours! hahaha\"\n",
    "aggression=True\n",
    "attack=True\n",
    "toxicity=True\n",
    "\n",
    "text_b=\"Make that four, fifth is underway.  This is rediculous!   \"\n",
    "aggression=True\n",
    "attack=False\n",
    "toxicity=True\n",
    "\n",
    "text_c=\"Indian people say this is just British hogwash.\"\n",
    "aggression=True\n",
    "attack=False\n",
    "toxicity=False\n",
    "\n",
    "text_d=\"Don't spam Wikipedia. I will block you if you add that stuff to Hentai again.\"\n",
    "aggression=True\n",
    "attack=False\n",
    "toxicity=False\n",
    "\n",
    "text_e=\"If you continue to vandalize MY TALK PAGE you will be blocked from living on the Earth. WAM! Thank you  \"\n",
    "aggression=False\n",
    "attack=True\n",
    "toxicity=False\n",
    "\n",
    "text_m=\"NEWLINE_TOKENNEWLINE_TOKEN== Pig Fenian ==NEWLINE_TOKENNEWLINE_TOKENNice wrist action boys, keep it up.\"\n",
    "aggression=False\n",
    "attack=False\n",
    "toxicity=True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x0000021761EEEF08>\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_examples_to_features\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(args.tokenizer_name)\n",
    "example=[]\n",
    "text=\"i have a dick, its bigger than yours! hahaha\"\n",
    "text = text.replace(\"NEWLINE_TOKEN\", \"\")\n",
    "text = text.replace(\"TAB_TOKEN\", \"\")\n",
    "label=['1','1','1']\n",
    "example.append(InputExample(guid=\"train-0\", text_a=text, text_b=None, label=label))\n",
    "label_list=[\"0\",\"1\"]\n",
    "features = convert_examples_to_features(example, tokenizer, label_list=label_list,\n",
    "                                                max_length=128, output_mode=\"classification\",\n",
    "                                                pad_on_left=False,\n",
    "                                                # pad on the left for xlnet\n",
    "                                                pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                pad_token_segment_id= 0, )\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "\n",
    "aggression_all_label=torch.tensor([f.aggression_label for f in features], dtype=torch.long)\n",
    "attack_all_label_label=torch.tensor([f.attack_label for f in features], dtype=torch.long)\n",
    "toxicity_all_label=torch.tensor([f.toxicity_label for f in features], dtype=torch.long)\n",
    "\n",
    "\n",
    "dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, aggression_all_label,attack_all_label_label,toxicity_all_label)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from multi_task_model import Multi_Model\n",
    "import numpy as np\n",
    "from utils import get_char_vocab,char2ids\n",
    "model=Multi_Model(args,config)\n",
    "args.device = torch.device(\"cpu\")\n",
    "\n",
    "checkpoint='./check_points/checkpoint-5950/model.pt'\n",
    "prefix = checkpoint.split('/')[-1] if checkpoint.find('checkpoint') != -1 else \"\"\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "aggression_tensor = torch.tensor(tokenizer.encode(\"aggression\"), dtype=torch.long).to(args.device)\n",
    "attack_tensor = torch.tensor(tokenizer.encode(\"attack\"), dtype=torch.long).to(args.device)\n",
    "toxicity_tensor = torch.tensor(tokenizer.encode(\"toxicity\"), dtype=torch.long).to(args.device)\n",
    "\n",
    "char_vocab = get_char_vocab()\n",
    "aggression_char_ids = char2ids(\"aggression\", char_vocab)\n",
    "attack_char_ids = char2ids(\"attack\", char_vocab)\n",
    "toxicity_char_ids = char2ids(\"toxicity\", char_vocab)\n",
    "\n",
    "aggression_char_tenor = torch.tensor(aggression_char_ids, dtype=torch.long).to(args.device)\n",
    "attack_char_tenor = torch.tensor(attack_char_ids, dtype=torch.long).to(args.device)\n",
    "toxicity_char_tenor = torch.tensor(toxicity_char_ids, dtype=torch.long).to(args.device)\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "model.to(args.device)\n",
    "for batch in dataloader:\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(args.device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1],'token_type_ids':batch[2], \n",
    "                  'aggression_labels': batch[3],'attack_labels': batch[4],\n",
    "                  'toxicity_labels': batch[5],'aggression_tensor': aggression_tensor, \n",
    "                  'attack_tensor': attack_tensor,'toxicity_tensor': toxicity_tensor, \n",
    "                  'aggression_char_tensor': aggression_char_tenor,\n",
    "                  'attack_char_tensor': attack_char_tenor, 'toxicity_char_tensor': toxicity_char_tenor}\n",
    "        aggression_logits, attack_logits, toxicity_logits, tmp_eval_loss,aggression_atten,attack_atten,toxicity_atten=model(**inputs)\n",
    "        print(aggression_atten.shape)\n",
    "    \n",
    "    aggression_preds = aggression_logits.detach().cpu().numpy()\n",
    "    aggression_out_label_ids = inputs['aggression_labels'].detach().cpu().numpy()\n",
    "    \n",
    "    attack_preds = attack_logits.detach().cpu().numpy()\n",
    "    attack_out_label_ids = inputs['attack_labels'].detach().cpu().numpy()\n",
    "\n",
    "    toxicity_preds = toxicity_logits.detach().cpu().numpy()\n",
    "    toxicity_out_label_ids = inputs['toxicity_labels'].detach().cpu().numpy()\n",
    "    \n",
    "aggression_preds = np.argmax(aggression_preds, axis=1)\n",
    "attack_preds = np.argmax(attack_preds, axis=1)\n",
    "toxicity_preds = np.argmax(toxicity_preds, axis=1)\n",
    "print(aggression_preds)\n",
    "print(attack_preds)\n",
    "print(toxicity_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'a', 'dick', ',', 'its', 'bigger', 'than', 'yours', '!', 'ha', '##ha', '##ha']\n",
      "[101, 1045, 2031, 1037, 5980, 1010, 2049, 7046, 2084, 6737, 999, 5292, 3270, 3270, 102]\n",
      "[101]\n"
     ]
    }
   ],
   "source": [
    "text=\"i have a dick, its bigger than yours! hahaha\"\n",
    "text = text.replace(\"NEWLINE_TOKEN\", \"\")\n",
    "text = text.replace(\"TAB_TOKEN\", \"\")\n",
    "print(tokenizer.tokenize(text))\n",
    "inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "           None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "        )\n",
    "print(inputs[\"input_ids\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
